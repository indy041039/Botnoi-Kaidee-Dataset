{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRAND_SCORE\n",
    "scaler = StandardScaler()\n",
    "scaled_score = scaler.fit_transform(train_df.groupby('brand').mean()['price'].values.reshape(-1, 1)).ravel()\n",
    "brand_score = pd.DataFrame()\n",
    "brand_score['brand'] = train_df.groupby('brand').mean()['price'].index\n",
    "brand_score['score'] = scaled_score\n",
    "brand_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_SCORE\n",
    "scaler = StandardScaler()\n",
    "scaled_score = scaler.fit_transform(train_df.groupby('model').mean()['price'].values.reshape(-1, 1)).ravel()\n",
    "model_score = pd.DataFrame()\n",
    "model_score['model'] = train_df.groupby('model').mean()['price'].index\n",
    "model_score['score2'] = scaled_score\n",
    "model_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOCATION_SCORE\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning (missing values, outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    clean = df.copy()\n",
    "    \n",
    "    # CLEAN MILEAGE\n",
    "    def fix_(x):\n",
    "        try:\n",
    "            x = int(x)\n",
    "        except:\n",
    "            x = np.nan\n",
    "        return x\n",
    "    clean['mileage'] = clean['mileage'].apply(lambda x: fix_(x))    \n",
    "    \n",
    "    # FILL MISSING VALUES\n",
    "    transmission_mode = clean['transmission'].mode()\n",
    "    color_mode = clean['color'].mode()\n",
    "    clean['desc'] = clean['desc'].fillna('')     \n",
    "    clean['transmission'] = clean['transmission'].fillna(transmission_mode)\n",
    "    clean['color'] = clean['color'].fillna(color_mode)\n",
    "    clean['mileage'] = clean['mileage'].fillna(clean['mileage'].mode()[0])\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = clean_data(train_df)\n",
    "test_data = clean_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(df):\n",
    "    feat = df.copy()\n",
    "    \n",
    "    #  TIMESTAMP\n",
    "    feat['timestamp'] = feat['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    # NEW NEW TIMESTAMP_YEAR COLUMNS\n",
    "    feat['timestamp_year'] = feat['timestamp'].apply(lambda x: x.year)\n",
    "    # CAR AGE COLUMNS\n",
    "    feat['age'] = feat['timestamp_year'] - feat['year']\n",
    "    feat = feat[feat['age']>=0]\n",
    "    \n",
    "    # CLEAR MILEAGE OUTLIER, FILL MISSING VALUES\n",
    "    q1 = feat['mileage'].quantile(0.25)\n",
    "    q3 = feat['mileage'].quantile(0.75)\n",
    "    IQR = q3-q1\n",
    "    upper_limit = q3+1.5*IQR\n",
    "    lower_limit = q1-1.5*IQR\n",
    "    outliers = (feat['mileage']>upper_limit) | (feat['mileage']<lower_limit)\n",
    "    feat = feat[~outliers]\n",
    "    \n",
    "#     nan_rows = feat['mileage'].isna()\n",
    "#     random_values = feat['mileage'][~nan_rows].values\n",
    "#     np.random.seed(0)\n",
    "#     random_mileage = np.random.choice(random_values, replace=True, size = sum(nan_rows))\n",
    "#     feat.loc[nan_rows, 'mileage'] = random_mileage\n",
    "        \n",
    "    # DESCRIPTION LENGTH\n",
    "    feat['length_desc'] = feat['desc'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    # MILEAGE PER YEAR\n",
    "    feat['mileage_per_year'] = feat['mileage']/feat['age']\n",
    "    feat['mileage_per_year'] = feat['mileage_per_year'].apply(lambda x: 0 if (x==np.inf) else x).fillna(0)\n",
    "    \n",
    "    #LOCATION\n",
    "    def sort_location(x):\n",
    "        if x not in ['กรุงเทพมหานคร']:\n",
    "            x = 'Other City'\n",
    "        return x\n",
    "    feat['location'] = feat['location'].apply(lambda x: sort_location(x))\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = extract_feature(train_data)\n",
    "test_feature = extract_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_feature['mileage'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRAND SCORE (BE AWARE OF DATA LEAKAGE !!)\n",
    "train_feature = pd.merge(train_feature, brand_score, how='inner')\n",
    "test_feature = pd.merge(test_feature, brand_score, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MODEL SCORE (BE AWARE OF DATA LEAKAGE !!)\n",
    "# train_feature = pd.merge(train_feature, model_score, how='inner')\n",
    "# test_feature = pd.merge(test_feature, model_score, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "scaler = MinMaxScaler()\n",
    "train_feature[['mileage','age','mileage_per_year']] = scaler.fit_transform(train_feature[['mileage','age','mileage_per_year']])\n",
    "test_feature[['mileage','age','mileage_per_year']] = scaler.transform(test_feature[['mileage','age','mileage_per_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_feature.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_feature(df, categorical_data, numerical_data):\n",
    "    get_feat = df.copy()\n",
    "    get_feat = get_feat[numerical_data + categorical_data]\n",
    "    #CATEGORICAL DATA\n",
    "    get_feat = pd.get_dummies(get_feat, columns=categorical_data)\n",
    "    return get_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = ['location','car_type']\n",
    "numerical_data = ['price','mileage','timestamp_year','mileage_per_year','score','age']\n",
    "train_feature_ = get_feature(train_feature, categorical_data, numerical_data)\n",
    "test_feature_ = get_feature(test_feature, categorical_data, numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_feature_.drop('price', axis=1)\n",
    "y = train_feature_['price']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_feature_.drop('price', axis=1)\n",
    "y_test = test_feature_['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, learning_rate, n_estimators, max_depth):\n",
    "    model =GradientBoostingRegressor(random_state=0, learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(X_train, y_train,0.1,100,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(y_val, prediction):\n",
    "    acc = mean_squared_error(y_val, prediction)\n",
    "    acc2 = r2_score(y_val, prediction)\n",
    "    return (acc, acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(learning_rate=0.1, n_estimators=100, max_depth=7):\n",
    "    model = train_model(X_train, y_train, learning_rate, n_estimators, max_depth)\n",
    "    prediction = model.predict(X_val)\n",
    "    acc = eval_acc(y_val, prediction)\n",
    "    \n",
    "    model = train_model(X, y, learning_rate, n_estimators, max_depth)\n",
    "    prediction = model.predict(X_test)\n",
    "    acc2 = eval_acc(y_test, prediction)\n",
    "    \n",
    "    return acc, acc2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc, acc2, model = pipeline(learning_rate=0.1, n_estimators=50, max_depth=4)\n",
    "print('Train dataset Validation')\n",
    "print('RMSE: ', np.sqrt(acc[0]))\n",
    "print('R-Squared: ', acc[1])\n",
    "print('-----------------------------------------------')\n",
    "print('Test dataset Validation')\n",
    "print('RMSE: ', np.sqrt(acc2[0]))\n",
    "print('R-Squared: ', acc2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame([X_train.columns, model.feature_importances_]).T\n",
    "feat_imp.columns = ['feature','importance']\n",
    "feat_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = []\n",
    "for i in range(0,15):\n",
    "    acc, acc2, model = pipeline(learning_rate=0.1, n_estimators=50, max_depth=i+1)\n",
    "    acc_array.append(acc[1])\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,16), acc_array)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('R-Squared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = []\n",
    "for i in [10,50,100,250,500,1000]:\n",
    "    acc, acc2, model = pipeline(learning_rate=0.1, n_estimators=i, max_depth=4)\n",
    "    acc_array.append(acc[1])\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([10,50,100,250,500,1000], acc_array)\n",
    "plt.xlabel('N_estimators')\n",
    "plt.ylabel('R-Squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = GradientBoostingRegressor(random_state=0, learning_rate=0.1, n_estimators=100, max_depth=7)\n",
    "rfecv = RFECV(estimator=est, step=1, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal Number of Features: ', rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_df = pd.DataFrame()\n",
    "rfecv_df['feature'] = X_train.columns\n",
    "rfecv_df['ranking'] = rfecv.ranking_\n",
    "rfecv_df.sort_values(by='ranking').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
